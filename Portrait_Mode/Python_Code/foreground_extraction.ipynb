{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "# Parameters\n",
    "H, W = 240, 320  # Replace with your actual image dimensions\n",
    "num_clusters = 10  # Number of clusters per pixel\n",
    "threshold = 10  # Distance threshold for matching a cluster\n",
    "initial_weight = 1.0 / num_clusters  # Evenly distribute the initial weight\n",
    "\n",
    "# Initialize a grayscale image frame\n",
    "frame = np.random.randint(0, 256, (H, W), dtype=np.int32)\n",
    "# changed data types to int32 because overflow was occurring before\n",
    "\n",
    "# Initialize clusters for each pixel\n",
    "clusters = np.zeros((H, W, num_clusters), dtype=[('centroid', np.int32), ('weight', np.float32)])\n",
    "clusters['centroid'] = np.repeat(frame[:, :, np.newaxis], num_clusters, axis=2)\n",
    "clusters['weight'] = initial_weight\n",
    "\n",
    "def manhattan_distance(a, b):\n",
    "    return np.abs(a - b)\n",
    "\n",
    "def normalize_weights(clusters):\n",
    "    \"\"\"\n",
    "    Normalize the weights of the clusters so they sum to one for each pixel.\n",
    "    :param clusters: The clusters array.\n",
    "    :return: The clusters with normalized weights.\n",
    "    \"\"\"\n",
    "    sum_weights = np.sum(clusters['weight'], axis=2, keepdims=True)\n",
    "    clusters['weight'] /= sum_weights\n",
    "    return clusters\n",
    "\n",
    "# Normalize the weights of the clusters\n",
    "clusters = normalize_weights(clusters)\n",
    "\n",
    "def match_and_update_clusters(new_frame, clusters, threshold, Height, Width, L=10):\n",
    "    \"\"\"\n",
    "    Match and update clusters according to the algorithm's adaptation step.\n",
    "    Args:\n",
    "        new_frame: The new incoming frame (grayscale).\n",
    "        clusters: The current clusters data structure.\n",
    "        threshold: The threshold for matching a cluster.\n",
    "        Height: The height of the frame.\n",
    "        Width: The width of the frame.\n",
    "        L: The parameter that controls the learning rate (the inverse of the learning rate).\n",
    "    \n",
    "    Returns:\n",
    "        Updated clusters and a boolean array indicating matched clusters.\n",
    "    \"\"\"\n",
    "    # Calculate the Manhattan distance to the new pixel values\n",
    "    distances = np.zeros((Height, Width, clusters.shape[2]))\n",
    "    for i in range(clusters.shape[2]):\n",
    "        distances[:,:,i] = manhattan_distance(new_frame, clusters['centroid'][:,:,i])\n",
    "    \n",
    "    # Find the cluster with the minimum distance for each pixel\n",
    "    min_distance_indices = np.argmin(distances, axis=2)\n",
    "    min_distances = np.take_along_axis(distances, min_distance_indices[:, :, np.newaxis], axis=2).squeeze()\n",
    "    \n",
    "    # Determine if the minimum distances are less than the threshold\n",
    "    matches = min_distances < threshold\n",
    "\n",
    "    locs = np.zeros((Height, Width), dtype=np.int32)\n",
    "    \n",
    "    # Update the clusters (weights and centroids)\n",
    "    for i in range(Height):\n",
    "        for j in range(Width):\n",
    "            if matches[i, j]:\n",
    "                matched_cluster = min_distance_indices[i, j]\n",
    "                locs[i, j] = matched_cluster\n",
    "                # Update the weights\n",
    "                for index in range(clusters.shape[2]):\n",
    "                    if (index == matched_cluster):\n",
    "                        clusters['weight'][i, j, index] += (1 / L) * (1 - clusters['weight'][i, j, index])\n",
    "                    else:\n",
    "                        clusters['weight'][i, j, index] -= (1 / L) * clusters['weight'][i, j, index]\n",
    "                \n",
    "                # Normalize weights to sum to 1 for all clusters\n",
    "                sum_weights = np.sum(clusters['weight'][i, j])\n",
    "                clusters['weight'][i, j] /= sum_weights\n",
    "                \n",
    "                # Update the centroid using approximation to avoid fractional centroids\n",
    "                # I did this because I didn't understand the shortcut to avoid fractional centroids lmao\n",
    "                clusters['centroid'][i, j, matched_cluster] += (1 / L) * (new_frame[i, j] - clusters['centroid'][i, j, matched_cluster])\n",
    "                clusters['centroid'][i, j, matched_cluster] = np.clip(clusters['centroid'][i, j, matched_cluster], 0, 255)\n",
    "            else:\n",
    "                # Find the cluster with the smallest weight and replace it\n",
    "                smallest_weight_idx = np.argmin(clusters['weight'][i, j])\n",
    "                locs[i,j] = smallest_weight_idx\n",
    "                clusters['centroid'][i, j, smallest_weight_idx] = new_frame[i, j]\n",
    "                clusters['weight'][i, j, smallest_weight_idx] = 1 / L\n",
    "                \n",
    "                # Normalize weights to sum to 1 for all clusters\n",
    "                sum_weights = np.sum(clusters['weight'][i, j])\n",
    "                clusters['weight'][i, j] /= sum_weights\n",
    "    \n",
    "    return clusters, locs\n",
    "\n",
    "def classify_pixels(clusters, locs, threshold=0.5):\n",
    "    \"\"\"\n",
    "    Classify each pixel as foreground or background.\n",
    "    \n",
    "    Args:\n",
    "        clusters: The clusters data structure containing centroids and weights.\n",
    "        locs: the locations of the matching clusters\n",
    "        threshold: The probability threshold to determine background.\n",
    "    \n",
    "    Returns:\n",
    "        A binary mask indicating foreground and background pixels.\n",
    "    \"\"\"\n",
    "    H, W, N = clusters['centroid'].shape  # Height, Width, and number of clusters\n",
    "    \n",
    "    # Initialize the probability image\n",
    "    P = np.zeros((H, W))\n",
    "    \n",
    "    # Find the cumulative sum of weights weighted higher than the matching weight\n",
    "    for i in range(H):\n",
    "        for j in range(W):\n",
    "            for k in range(N):\n",
    "                if (clusters['weight'][i, j, k] > clusters['weight'][i, j, locs[i, j]]):\n",
    "                    P[i, j] += clusters['weight'][i, j, k]\n",
    "    \n",
    "    # Create a binary mask based on the threshold\n",
    "    binary_mask = np.zeros((H, W), dtype=np.uint8)\n",
    "    binary_mask[P > threshold] = 255  # Foreground\n",
    "    binary_mask[P <= threshold] = 0  # Background\n",
    "    \n",
    "    return binary_mask\n",
    "\n",
    "\n",
    "# Simulate a new incoming frame\n",
    "new_frame = np.random.randint(0, 256, (H, W), dtype=np.int32)\n",
    "\n",
    "# Perform cluster matching and updating\n",
    "test_clusters, test_locs = match_and_update_clusters(new_frame, clusters, threshold, H, W)\n",
    "\n",
    "\n",
    "# Let's assume a background threshold. This value might need tuning for different scenarios\n",
    "background_threshold = 0.100001  # Example threshold\n",
    "\n",
    "# Perform classification\n",
    "binary_mask = classify_pixels(clusters, test_locs, background_threshold)\n",
    "# print(binary_mask.shape, binary_mask.dtype)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.imshow(binary_mask, cmap='gray', vmin=0, vmax=255)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def postprocess_segmentation(binary_mask, min_area_threshold=50):\n",
    "    \"\"\"\n",
    "    Post-process the binary segmentation mask according to the described algorithm.\n",
    "    \n",
    "    Args:\n",
    "        binary_mask: Binary mask with foreground as white (255) and background as black (0).\n",
    "        min_area_threshold: Minimum area threshold to keep a blob.\n",
    "    \n",
    "    Returns:\n",
    "        Cleaned binary mask.\n",
    "    \"\"\"\n",
    "\n",
    "    kernel_open = np.ones((2,2), np.uint8)\n",
    "    opened = cv2.morphologyEx(binary_mask, cv2.MORPH_OPEN, kernel_open)\n",
    "    # Join pixels that are separated by a single gap\n",
    "    # kernel = np.ones((2,2), np.uint8)\n",
    "    # closed = cv2.morphologyEx(opened, cv2.MORPH_CLOSE, kernel)\n",
    "    \n",
    "    # Find contours from the binary mask\n",
    "    contours, _ = cv2.findContours(opened, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
    "    \n",
    "    # Create an empty mask to draw the retained contours\n",
    "    mask = np.zeros_like(binary_mask)\n",
    "    \n",
    "    # Filter out small contours and draw the rest on the mask\n",
    "    for contour in contours:\n",
    "        if cv2.contourArea(contour) > min_area_threshold:\n",
    "            cv2.drawContours(mask, [contour], -1, (255), thickness=cv2.FILLED)\n",
    "    \n",
    "    return mask\n",
    "\n",
    "#def postprocess_segmentation(binary_mask):\n",
    "    \"\"\"\n",
    "    Post-process the binary segmentation mask.\n",
    "    :param binary_mask: Binary mask with foreground as white (255) and background as black (0).\n",
    "    :return: Cleaned binary mask.\n",
    "    \"\"\"\n",
    "    # Define kernel for morphological operations\n",
    "    kernel = np.ones((3,3), np.uint8)\n",
    "    \n",
    "    # Remove noise (small white spots in the background)\n",
    "    opening = cv2.morphologyEx(binary_mask, cv2.MORPH_OPEN, kernel, iterations=2)\n",
    "    \n",
    "    # Close small holes in the foreground objects (small black spots in the foreground)\n",
    "    closing = cv2.morphologyEx(opening, cv2.MORPH_CLOSE, kernel, iterations=2)\n",
    "    \n",
    "    # Optionally, remove small blobs by setting a minimum area threshold\n",
    "    # num_labels, labels, stats, centroids = cv2.connectedComponentsWithStats(closing, connectivity=8)\n",
    "    \n",
    "    # min_area_threshold = 50  # minimum area in pixels for a blob to be kept\n",
    "    # for i in range(1, num_labels):  # label 0 is the background label, so we start from 1\n",
    "    #     if stats[i, cv2.CC_STAT_AREA] < min_area_threshold:\n",
    "    #         closing[labels == i] = 0\n",
    "    \n",
    "    return closing\n",
    "\n",
    "\n",
    "# Assume 'binary_mask' is the binary mask from the classification step\n",
    "# Apply the post-processing routine to clean up the segmentation result\n",
    "cleaned_binary_mask = postprocess_segmentation(binary_mask)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def initialize_clusters(cap, num_clusters_per_pixel, frame_height, frame_width):\n",
    "    # Initialize the centroids array\n",
    "    centroids = np.zeros((frame_height, frame_width, num_clusters_per_pixel), dtype=np.uint8)\n",
    "    weights = np.full((frame_height, frame_width, num_clusters_per_pixel), 1.0 / num_clusters_per_pixel, dtype=np.float32)\n",
    "    \n",
    "    # Read the first n frames to set as initial centroids\n",
    "    for c in range(num_clusters_per_pixel):\n",
    "        ret, frame = cap.read()\n",
    "        if not ret:\n",
    "            raise ValueError(\"Not enough frames in video to initialize clusters.\")\n",
    "        gray_frame = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
    "        centroids[:, :, c] = gray_frame\n",
    "    \n",
    "    return centroids, weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current Frame: 271 / 276\n",
      "Finished\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Actual code to run it\n",
    "\n",
    "# Video processing setup\n",
    "video_path = 'titanic_test.mp4'\n",
    "cap = cv2.VideoCapture(video_path)\n",
    "frame_height, frame_width = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT)), int(cap.get(cv2.CAP_PROP_FRAME_WIDTH))\n",
    "H, W = frame_height, frame_width\n",
    "num_clusters_per_pixel = 5\n",
    "threshold = 20\n",
    "\n",
    "# length = int(cap.get(cv2.CAP_PROP_FRAME_COUNT))\n",
    "# print( length )\n",
    "\n",
    "initial_centroids, initial_weights = initialize_clusters(cap, num_clusters_per_pixel, frame_height, frame_width)\n",
    "\n",
    "total_frames = int(cap.get(cv2.CAP_PROP_FRAME_COUNT))\n",
    "\n",
    "# Prepare video writer\n",
    "fourcc = cv2.VideoWriter_fourcc(*'XVID')\n",
    "out = cv2.VideoWriter('output.avi', fourcc, 30.0, (frame_width, frame_height), isColor=False)\n",
    "\n",
    "# Initialize clusters structure\n",
    "clusters = np.zeros((frame_height, frame_width, num_clusters_per_pixel),\n",
    "                    dtype=[('centroid', np.int32), ('weight', np.float32)])\n",
    "clusters['centroid'] = initial_centroids\n",
    "clusters['weight'] = initial_weights\n",
    "frame_num = 0\n",
    "while cap.isOpened():\n",
    "    frame_num+=1\n",
    "    ret, frame = cap.read()\n",
    "    if not ret:\n",
    "        break\n",
    "\n",
    "    gray_frame = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
    "    # Assuming the existence of matching, adaptation, classification, and post-processing functions\n",
    "    clusters, locs = match_and_update_clusters(gray_frame, clusters, threshold, gray_frame.shape[0], gray_frame.shape[1], 100)\n",
    "    # Normalization happens in match_and_update_clusters\n",
    "    binary_mask = classify_pixels(clusters, locs, 0.6)\n",
    "    cleaned_binary_mask = postprocess_segmentation(binary_mask)\n",
    "\n",
    "    print(f'\\rCurrent Frame: {frame_num} / {total_frames}', end='')\n",
    "    out.write(cleaned_binary_mask)  # Save the processed frame\n",
    "    cv2.imshow('Pre-Processed Frame', binary_mask)\n",
    "    cv2.imshow('Post-Processed Frame', cleaned_binary_mask)\n",
    "    cv2.imshow('Raw Frame', gray_frame)\n",
    "    if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "        break\n",
    "\n",
    "print('\\nFinished\\n')\n",
    "cap.release()\n",
    "out.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
